{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c7f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data prep\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6c865ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "data_ann=r\"C:\\Users\\ASUS\\Desktop\\DATASETS\\HAGRID\\ann_subsample.json\"\n",
    "df1 = pd.read_json(data_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f707fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(data_ann)\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7d60bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2={}\n",
    "for key,value,orikey in zip(range(1,1801),data.values(),data.keys()):   \n",
    "    data2[key]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c87ea988",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bboxes': [[0.31154288, 0.46630872, 0.07549231, 0.15199647]],\n",
       " 'labels': ['dislike'],\n",
       " 'leading_hand': 'right',\n",
       " 'leading_conf': 1.0,\n",
       " 'user_id': 'e5ccc395b60e4a8a78f0ca6a76c2db62'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb3a690c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[45]['labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f70c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image, bbox, box_scale=1.):\n",
    "    width, height = image.size\n",
    "    x1, y1, w, h = bbox\n",
    "    bbox_abs = [x1 * width, y1 * height, (x1 + w) * width, (y1 + h) * height]\n",
    "    int_bbox = np.array(bbox_abs).round().astype(np.int32)\n",
    "    x1 = int_bbox[0]\n",
    "    y1 = int_bbox[1]\n",
    "    x2 = int_bbox[2]\n",
    "    y2 = int_bbox[3]\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    w = h = max(x2 - x1, y2 - y1)\n",
    "    x1 = max(0, cx - box_scale * w // 2)\n",
    "    y1 = max(0, cy - box_scale * h // 2)\n",
    "    x2 = cx + box_scale * w // 2\n",
    "    y2 = cy + box_scale * h // 2\n",
    "    x1, y1, x2, y2 = list(map(int, (x1, y1, x2, y2)))\n",
    "\n",
    "    crop_image = image.crop((x1, y1, x2, y2))\n",
    "    bbox_orig = np.array([x1, y1, x2, y2]).reshape(2, 2)\n",
    "#     #crop_image = crop_image.resize((224,224))\n",
    "    return crop_image\n",
    "# , bbox_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f171659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in data2.items():\n",
    "    img = Image.open(r\"D:\\YOLO_Hagrid\\texts4\\{}.jpg\".format(key))\n",
    "    \n",
    "    if(len(value['labels'])>=2):\n",
    "        data = value\n",
    "        box1 = value['bboxes'][0]\n",
    "        box2 = value['bboxes'][1]\n",
    "        if(value['labels'][0]=='no_gesture'):\n",
    "            folder1 = r\"C:/Users/ASUS/DVCon/gesture_recognition_data_prep_and_classification/images/no_gesture/\"\n",
    "            folder2 = r\"C:/Users/ASUS/DVCon/gesture_recognition_data_prep_and_classification/images/{}/\".format(data['labels'][1])\n",
    "            #cropped image\n",
    "            img1 = crop(img,box1)\n",
    "            img1.save(folder+str(key)+\".jpg\")\n",
    "            img2 =crop(img,box2)\n",
    "            img2.save(folder2+str(key)+\".jpg\")\n",
    "        else:\n",
    "            folder2 = r\"C:/Users/ASUS/DVCon/gesture_recognition_data_prep_and_classification/images/no_gesture\"\n",
    "            folder1 = r\"C:/Users/ASUS/DVCon/gesture_recognition_data_prep_and_classification/images/{}/\".format(data['labels'][0])\n",
    "            #cropped image\n",
    "            img2 = crop(img,box2)\n",
    "            img2.save(folder2+str(key)+\".jpg\")\n",
    "            img1 =crop(img,box1)\n",
    "            img1.save(folder1+str(key)+\".jpg\")            \n",
    "    else:\n",
    "        data = value\n",
    "        box = value['bboxes'][0] \n",
    "        folder = r\"C:/Users/ASUS/DVCon/gesture_recognition_data_prep_and_classification/images/{}/\".format(data['labels'][0])\n",
    "        # cropped image\n",
    "        img = crop(img,box)\n",
    "        img.save(folder+str(key)+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f5e367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8182c984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8af86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf6d310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf8d7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3551714d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd2f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8f4a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7e0e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classifying the classses\n",
    "# for key,value in data2.items():\n",
    "#     img = Image.open(r\"D:\\YOLO_Hagrid\\texts4\\{}.jpg\".format(key))\n",
    "#     for i in range(len(value['bboxes'])):\n",
    "#         data = value\n",
    "#         box = value['bboxes'][i] \n",
    "        \n",
    "#         folder = r\"C:/Users/ASUS/DVCon/gesture_recognition_data_prep_and_classification/images/{}/\".format(data['labels'][i])\n",
    "#         # cropped image\n",
    "#         img = crop(img,box)\n",
    "#         try:\n",
    "#             img.save(folder+str(key)+\".jpg\")\n",
    "#         except:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /DVCon/gesture_recognition_data_prep_and_classification/images/call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a2a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\ASUS\\DVCon\\gesture_recognition_data_prep_and_classification\\images\\call"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
